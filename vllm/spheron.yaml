version: "1.0"

services:
  vllm:
    image: vllm/vllm-openai:latest
    pull_policy: IfNotPresent
    expose:
      - port: 3000
        as: 3000
        to:
          - global: true
    args:
      - --model
      - <model_name>
      - --port
      - "3000"
    env:
      - HUGGING_FACE_HUB_TOKEN=<hugging_face_hub_token>
    params:
      storage:
        default:
          mount: /mnt/data
          readOnly: false
profiles:
  name: vllm-deployment
  duration: 2h
  mode: provider
  compute:
    vllm:
      resources:
        cpu:
          units: 8
        memory:
          size: 16Gi
        storage:
          name: "default"
          size: 120Gi
          attributes:
            persistent: true
            class: beta3
        gpu:
          units: 1
          attributes:
            vendor:
              nvidia:
                - model: rtx6000-ada
  placement:
    westcoast:
      pricing:
        vllm:
          token: uSPON
          amount: 1.5

deployment:
  vllm:
    westcoast:
      profile: vllm
      count: 1
