version: "1.0"

services:
  vllmserver:
    image: vllm/vllm-openai:latest
    pull_policy: Always
    expose:
      - port: 8000
        as: 8000
        to:
          - global: true
    env:
      - MODEL_NAME=mistralai/Mistral-7B-Instruct-v0.3
      - HUGGING_FACE_HUB_TOKEN=
    command:
      - /bin/bash
      - -c
      - |
        # Find Python executable
        PYTHON_PATH=$(which python3 || which python || echo "/usr/bin/python3")
        echo "Using Python at: $PYTHON_PATH"

        # Start vLLM server
        $PYTHON_PATH -m vllm.entrypoints.openai.api_server \
          --model ${MODEL_NAME} \
          --host 0.0.0.0 \
          --port 8000
profiles:
  name: vllmserver
  duration: 1h
  mode: provider
  compute:
    vllmserver:
      resources:
        cpu:
          units: 8
        memory:
          size: 32Gi
        storage:
          - size: 200Gi
        gpu:
          units: 1
          attributes:
            vendor:
              nvidia:
                - model: rtx6000-ada
  placement:
    westcoast:
      pricing:
        vllmserver:
          token: uSPON
          amount: 1

deployment:
  vllmserver:
    westcoast:
      profile: vllmserver
      count: 1